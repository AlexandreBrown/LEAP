defaults:
  - _self_
  - base_config
experiment:
  name: "tdm_training"
env:
  name: "AntMaze_UMaze-v4"
  device: "cpu"
  obs:
    height: 128
    width: 128
    raw_height: 480
    raw_width: 480
    dim: 3
    normalize: True
    standardization_stats_init_iter: 0
    standardize: False
  goal:
    latent_dim: 512
    reached_epsilon: 0.1
    x_min_max: [-0.14, 0.14]
    y_min_max: [-0.2, 0.2]
    z_min_max: [0.07, 0.25]
  keys_of_interest: ["observation", "pixels_latent", "state", "action", "goal_latent", "planning_horizon", "reward", "done"]
  camera:
    distance: 0.5
replay_buffer:
  max_size: 1_000_000
train:
  num_episodes: 3000
  initial_max_planning_horizon: 32
  planning_horizon_annealing: True
  planning_horizon_annealing_cycles: 1
  planning_horizon_annealing_ratio: 0.5
  max_frames_per_traj: 128
  init_random_frames: 0
  frames_per_batch: 512
  reset_at_each_iter: False
  collector_device: "cpu"
  storing_device: "cpu"
  updates_per_step: 20
  reward_norm_type: "l1"
  train_batch_size: 128
  target_update_freq: 8
  actor_learning_rate: 1e-4
  critic_learning_rate: 1e-3
  polyak_avg: 0.99
  noise_mean: 0
  noise_std: 1.0
  target_policy_action_noise_clip: 0.5
  target_policy_action_noise_std: 0.2
  noise_annealing_frames: 3000
  alg: 'tdm_td3'
  use_relabeling: True
models:
  device: "cuda"
  encoder_decoder:
    name: "vae_best_model_antmaze_umaze-v4"
    version: "1.0.0"
    download_path: "models/encoder_decoder/"
    encoder:
      hidden_dims: [16, 32, 64, 128]
      hidden_activation: "leaky_relu"
      leaky_relu_neg_slope: 0.2
      hidden_kernels: [4, 4, 4, 4]
      hidden_strides: [2, 2, 2, 2]
      hidden_paddings: [1, 1, 1, 1]
      use_batch_norm: True
    decoder:
      hidden_dims: [64, 32, 16]
      hidden_activation: "relu"
      hidden_kernels: [4, 4, 4]
      hidden_strides: [2, 2, 2]
      hidden_paddings: [1, 1, 1]
      output_kernel: 4
      output_stride: 2
      output_padding: 1
      use_batch_norm: True
  actor:
    model_type: "mlp_pretrained_encoder"
    hidden_layers_out_features: [256, 256, 256]
    hidden_activation_function_name: "relu"
    output_activation_function_name: "tanh"
    in_keys: ["pixels_latent", "state", "goal_latent", "planning_horizon"]
  critic:
    model_type: "mlp_pretrained_encoder"
    hidden_layers_out_features: [256, 256, 256]
    hidden_activation_function_name: "relu"
    use_batch_norm: True
    output_activation_function_name: "identity"
    in_keys: ["pixels_latent", "state", "action", "goal_latent", "planning_horizon"]
    relative: True
logging:
  video_log_step_freq: 1
  video_frames: 300