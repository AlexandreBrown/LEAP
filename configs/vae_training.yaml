defaults:
  - _self_
  - base_config
experiment:
  name: "vae_training"
env:
  name: "AntMaze_UMaze-v4"
dataset:
  path: "datasets/vae_dataset_65536.h5"
  normalize: True
  height: 128
  width: 128
training:
  train_val_split: 0.25
  train_batch_size: 512
  val_batch_size: 1024
  epochs: 100
  kl_divergence_beta: 1
  kl_divergence_annealing_strategy: "cyclic_linear"
  kl_divergence_annealing_cycles: 4
  kl_divergence_annealing_ratio: 0.5
  reconstruction_loss: "mse"
model:
  optimizer:
    name: "adam"
    lr: 0.001
  input_channels: 3
  latent_dim: 1024
  save_dir: "models/"
  encoder:
    hidden_dims: [16, 32, 64, 128]
    hidden_activation: "leaky_relu"
    leaky_relu_neg_slope: 0.2
    hidden_kernels: [4, 4, 4, 4]
    hidden_strides: [2, 2, 2, 2]
    hidden_paddings: [1, 1, 1, 1]
    use_batch_norm: True
  decoder:
    hidden_dims: [64, 32, 16]
    hidden_activation: "relu"
    hidden_kernels: [4, 4, 4]
    hidden_strides: [2, 2, 2]
    hidden_paddings: [1, 1, 1]
    output_kernel: 4
    output_stride: 2
    output_padding: 1
    use_batch_norm: True
logging:
  val_image_log_steps_interval: 50
  val_num_preview_samples: 6
