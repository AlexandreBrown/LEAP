{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models.vae.model import VAEEncoder, VAEDecoder\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder Parameters Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv + Linear HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3 \n",
    "encoder_hidden_dims = [16, 32, 64, 128, 256, 512]\n",
    "encoder_kernels = [1, 5, 5, 4, 3, 4]\n",
    "encoder_strides = [1, 1, 1, 2, 2, 1]\n",
    "encoder_paddings = [0, 0, 0, 0, 0, 0]\n",
    "encoder_last_layer_fc = True\n",
    "encoder_last_spatial_dim = 26\n",
    "latent_dim = 64\n",
    "decoder_hidden_dims= [512, 256, 128, 64, 32, 16]\n",
    "decoder_kernels = [-1, 4, 3, 4, 5, 5, 4]\n",
    "decoder_strides = [-1, 1, 2, 2, 1, 1, 1]\n",
    "decoder_paddings = [-1, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv only HParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 3 \n",
    "encoder_hidden_dims = [16, 32, 64, 128, 256, 512]\n",
    "encoder_kernels = [1, 5, 5, 4, 3, 4]\n",
    "encoder_strides = [1, 1, 1, 2, 2, 1]\n",
    "encoder_paddings = [0, 0, 0, 0, 0, 0]\n",
    "encoder_last_layer_fc = False\n",
    "encoder_last_spatial_dim = 26\n",
    "latent_dim = 64\n",
    "decoder_hidden_dims= [256, 128, 64, 32, 16, 16]\n",
    "decoder_kernels = [4, 3, 4, 5, 5, 4]\n",
    "decoder_strides = [1, 2, 2, 1, 1, 1]\n",
    "decoder_paddings = [0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = VAEEncoder(input_dim=input_dim, \n",
    "                    encoder_hidden_dims=encoder_hidden_dims,\n",
    "                    encoder_kernels=encoder_kernels,\n",
    "                    encoder_strides=encoder_strides,\n",
    "                    encoder_paddings=encoder_paddings,\n",
    "                    encoder_last_layer_fc=encoder_last_layer_fc,\n",
    "                    encoder_last_spatial_dim=encoder_last_spatial_dim,\n",
    "                    latent_dim=latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10, input_dim, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal(loc: torch.Size([10, 64]), scale: torch.Size([10, 64]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder (Conv only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VAEEncoder                               [10, 64, 26, 26]          32,832\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Conv2d: 2-1                       [10, 16, 128, 128]        64\n",
       "│    └─Conv2d: 2-2                       [10, 32, 124, 124]        12,832\n",
       "│    └─Conv2d: 2-3                       [10, 64, 120, 120]        51,264\n",
       "│    └─Conv2d: 2-4                       [10, 128, 59, 59]         131,200\n",
       "│    └─Conv2d: 2-5                       [10, 256, 29, 29]         295,168\n",
       "│    └─Conv2d: 2-6                       [10, 512, 26, 26]         2,097,664\n",
       "├─Conv2d: 1-2                            [10, 64, 26, 26]          32,832\n",
       "==========================================================================================\n",
       "Total params: 2,653,856\n",
       "Trainable params: 2,653,856\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 30.82\n",
       "==========================================================================================\n",
       "Input size (MB): 1.97\n",
       "Forward/backward pass size (MB): 218.08\n",
       "Params size (MB): 10.48\n",
       "Estimated Total Size (MB): 230.53\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(encoder, input_size=(10, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Conv + Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VAEEncoder                               [10, 64]                  22,151,232\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Conv2d: 2-1                       [10, 16, 128, 128]        64\n",
       "│    └─Conv2d: 2-2                       [10, 32, 124, 124]        12,832\n",
       "│    └─Conv2d: 2-3                       [10, 64, 120, 120]        51,264\n",
       "│    └─Conv2d: 2-4                       [10, 128, 59, 59]         131,200\n",
       "│    └─Conv2d: 2-5                       [10, 256, 29, 29]         295,168\n",
       "│    └─Conv2d: 2-6                       [10, 512, 26, 26]         2,097,664\n",
       "├─Linear: 1-2                            [10, 64]                  22,151,232\n",
       "==========================================================================================\n",
       "Total params: 46,890,656\n",
       "Trainable params: 46,890,656\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 30.82\n",
       "==========================================================================================\n",
       "Input size (MB): 1.97\n",
       "Forward/backward pass size (MB): 214.63\n",
       "Params size (MB): 98.96\n",
       "Estimated Total Size (MB): 315.55\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(encoder, input_size=(10, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = VAEDecoder(input_dim=input_dim,\n",
    "                    encoder_last_layer_fc=encoder_last_layer_fc,\n",
    "                    encoder_last_spatial_dim=encoder_last_spatial_dim,\n",
    "                    latent_dim=latent_dim,\n",
    "                    decoder_hidden_dims=decoder_hidden_dims,\n",
    "                    decoder_kernels=decoder_kernels,\n",
    "                    decoder_strides=decoder_strides,\n",
    "                    decoder_paddings=decoder_paddings,\n",
    "                    decoder_output_sigmoid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_z = encoder(x)\n",
    "z = q_z.rsample()\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder (Conv only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VAEDecoder                               [10, 3, 131, 131]         --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─ConvTranspose2d: 2-1              [10, 256, 29, 29]         262,400\n",
       "│    └─ConvTranspose2d: 2-2              [10, 128, 59, 59]         295,040\n",
       "│    └─ConvTranspose2d: 2-3              [10, 64, 120, 120]        131,136\n",
       "│    └─ConvTranspose2d: 2-4              [10, 32, 124, 124]        51,232\n",
       "│    └─ConvTranspose2d: 2-5              [10, 16, 128, 128]        12,816\n",
       "│    └─ConvTranspose2d: 2-6              [10, 16, 131, 131]        4,112\n",
       "├─ConvTranspose2d: 1-2                   [10, 3, 131, 131]         51\n",
       "==========================================================================================\n",
       "Total params: 756,787\n",
       "Trainable params: 756,787\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 42.05\n",
       "==========================================================================================\n",
       "Input size (MB): 1.73\n",
       "Forward/backward pass size (MB): 213.02\n",
       "Params size (MB): 3.03\n",
       "Estimated Total Size (MB): 217.77\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(decoder, input_size=(10, latent_dim, encoder_last_spatial_dim, encoder_last_spatial_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoder (Conv + Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VAEDecoder                               [10, 3, 128, 128]         --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Linear: 2-1                       [10, 346112]              22,497,280\n",
       "│    └─ConvTranspose2d: 2-2              [10, 256, 29, 29]         2,097,408\n",
       "│    └─ConvTranspose2d: 2-3              [10, 128, 59, 59]         295,040\n",
       "│    └─ConvTranspose2d: 2-4              [10, 64, 120, 120]        131,136\n",
       "│    └─ConvTranspose2d: 2-5              [10, 32, 124, 124]        51,232\n",
       "│    └─ConvTranspose2d: 2-6              [10, 16, 128, 128]        12,816\n",
       "├─ConvTranspose2d: 1-2                   [10, 3, 128, 128]         51\n",
       "==========================================================================================\n",
       "Total params: 25,084,963\n",
       "Trainable params: 25,084,963\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 57.00\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 218.55\n",
       "Params size (MB): 100.34\n",
       "Estimated Total Size (MB): 318.89\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(decoder, input_size=(10, latent_dim))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
